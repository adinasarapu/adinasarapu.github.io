

<!doctype html>
<html lang="en" class="no-js">
  <head>
    

<meta charset="utf-8">



<!-- begin SEO -->









<title>Building a real-time big data pipeline (1: Kafka, RESTful, Java) - Ashok R. Dinasarapu Ph.D</title>







<meta property="og:locale" content="en-US">
<meta property="og:site_name" content="Ashok R. Dinasarapu Ph.D">
<meta property="og:title" content="Building a real-time big data pipeline (1: Kafka, RESTful, Java)">


  <link rel="canonical" href="https://adinasarapu.github.io/posts/2020/01/blog-post-kafka/">
  <meta property="og:url" content="https://adinasarapu.github.io/posts/2020/01/blog-post-kafka/">



  <meta property="og:description" content="Updated on September 20, 2021">





  

  





  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2020-04-05T00:00:00-04:00">








  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Ashok R. Dinasarapu",
      "url" : "https://adinasarapu.github.io",
      "sameAs" : null
    }
  </script>






<!-- end SEO -->


<link href="https://adinasarapu.github.io/feed.xml" type="application/atom+xml" rel="alternate" title="Ashok R. Dinasarapu Ph.D Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="https://adinasarapu.github.io/assets/css/main.css">

<meta http-equiv="cleartype" content="on">
    

<!-- start custom head snippets -->

<link rel="apple-touch-icon" sizes="57x57" href="https://adinasarapu.github.io/images/apple-touch-icon-57x57.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="60x60" href="https://adinasarapu.github.io/images/apple-touch-icon-60x60.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="72x72" href="https://adinasarapu.github.io/images/apple-touch-icon-72x72.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="76x76" href="https://adinasarapu.github.io/images/apple-touch-icon-76x76.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="114x114" href="https://adinasarapu.github.io/images/apple-touch-icon-114x114.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="120x120" href="https://adinasarapu.github.io/images/apple-touch-icon-120x120.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="144x144" href="https://adinasarapu.github.io/images/apple-touch-icon-144x144.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="152x152" href="https://adinasarapu.github.io/images/apple-touch-icon-152x152.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="180x180" href="https://adinasarapu.github.io/images/apple-touch-icon-180x180.png?v=M44lzPylqQ">
<link rel="icon" type="image/png" href="https://adinasarapu.github.io/images/favicon-32x32.png?v=M44lzPylqQ" sizes="32x32">
<link rel="icon" type="image/png" href="https://adinasarapu.github.io/images/android-chrome-192x192.png?v=M44lzPylqQ" sizes="192x192">
<link rel="icon" type="image/png" href="https://adinasarapu.github.io/images/favicon-96x96.png?v=M44lzPylqQ" sizes="96x96">
<link rel="icon" type="image/png" href="https://adinasarapu.github.io/images/favicon-16x16.png?v=M44lzPylqQ" sizes="16x16">
<link rel="manifest" href="https://adinasarapu.github.io/images/manifest.json?v=M44lzPylqQ">
<link rel="mask-icon" href="https://adinasarapu.github.io/images/safari-pinned-tab.svg?v=M44lzPylqQ" color="#000000">
<link rel="shortcut icon" href="/images/favicon.ico?v=M44lzPylqQ">
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-TileImage" content="https://adinasarapu.github.io/images/mstile-144x144.png?v=M44lzPylqQ">
<meta name="msapplication-config" content="https://adinasarapu.github.io/images/browserconfig.xml?v=M44lzPylqQ">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="https://adinasarapu.github.io/assets/css/academicons.css"/>

<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>

<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg"><a href="https://adinasarapu.github.io/">Ashok R. Dinasarapu Ph.D</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://adinasarapu.github.io/publications/">Publications</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://adinasarapu.github.io/teaching/">Teaching</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://adinasarapu.github.io/portfolio/">Big Data</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://adinasarapu.github.io/year-archive/">NGS | Proteomics</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://adinasarapu.github.io/cv/">Résumé</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    





<div id="main" role="main">
  


  <div class="sidebar sticky">
  



<div itemscope itemtype="http://schema.org/Person">

  <div class="author__avatar">
    
    	<img src="https://adinasarapu.github.io/images/profile.png" class="author__avatar" alt="Scientist, Bioinformatics">
    
  </div>

  <div class="author__content">
    <h3 class="author__name">Scientist, Bioinformatics</h3>
    <p class="author__bio">Bridging the gap between Genomics and Data Science</p>
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> Atlanta, GA</li>
      
      
      
      
        <li><a href="mailto:ashok.reddy.dinasarapu@emory.edu"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i> Email</a></li>
      
      
       
        <li><a href="https://www.researchgate.net/profile/Ashok_Dinasarapu"><i class="fab fa-fw fa-researchgate" aria-hidden="true"></i> ResearchGate</a></li>
      
      
        <li><a href="https://twitter.com/adinasarapu"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
      
      
      
      
        <li><a href="https://www.linkedin.com/in/dareddy"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
      
      
      
      
      
        <li><a href="https://bitbucket.org/adinasarapu"><i class="fab fa-fw fa-bitbucket" aria-hidden="true"></i> Bitbucket</a></li>
      
      
        <li><a href="https://github.com/adinasarapu"><i class="fab fa-fw fa-github" aria-hidden="true"></i> Github</a></li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
        <li><a href="https://scholar.google.com/citations?user=b6GBykAAAAAJ"><i class="fas fa-fw fa-graduation-cap"></i> Google Scholar</a></li>
      
      
        <li><a href="https://pubmed.ncbi.nlm.nih.gov/?term=dinasarapu+ashok+OR+D+ashok+reddy&sort=pubdate"><i class="ai ai-pubmed-square ai-fw"></i> PubMed</a></li>
      
      
        <li><a href="http://orcid.org/0000-0002-1423-1518"><i class="ai ai-orcid-square ai-fw"></i> ORCID</a></li>
      
      
      
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="Building a real-time big data pipeline (1: Kafka, RESTful, Java)">
    <meta itemprop="description" content="Updated on September 20, 2021">
    <meta itemprop="datePublished" content="April 05, 2020">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 class="page__title" itemprop="headline">Building a real-time big data pipeline (1: Kafka, RESTful, Java)
</h1>
          
        
        
        
          <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2020-04-05T00:00:00-04:00">April 05, 2020</time></p>
        
        
             
        
    
        </header>
      

      <section class="page__content" itemprop="text">
        <p><em>Updated on September 20, 2021</em></p>

<p><a href="https://kafka.apache.org">Apache Kafka</a> is used for building real-time data pipelines and streaming <em>apps</em>. Kafka helps transmit messages from one system to another (a message broker). Zookeeper is required to run a Kafka Cluster. <a href="https://zookeeper.apache.org">Apache ZooKeeper</a> is primarily used to track the status of nodes in the Kafka Cluster and maintain a list of Kafka <em>topics</em> and <em>messages</em>. Starting with v2.8, Kafka can be run without ZooKeeper. However, this update isn’t ready for use in production.</p>

<p><strong>Kafka for local development of applications</strong>:</p>

<p>There are multiple ways of running Kafka locally for development of <em>apps</em> but the easiest method is by <code class="language-plaintext highlighter-rouge">docker-compose</code>. First download <em>Docker Desktop</em>, <a href="https://hub.docker.com/">Docker Hub</a> and SignIn with Docker ID. Docker Compose is included as part of this desktop. <code class="language-plaintext highlighter-rouge">docker-compose</code> facilitates installing <code class="language-plaintext highlighter-rouge">Kafka</code> and <code class="language-plaintext highlighter-rouge">Zookeeper</code> with the help of <code class="language-plaintext highlighter-rouge">docker-compose.yml</code> file.</p>

<p>Create a file called <code class="language-plaintext highlighter-rouge">docker-compose.yml</code> in your project directory and paste the following:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>version: '3'  
services:  
  zookeeper:  
    image: wurstmeister/zookeeper  
    ports:  
      - "2181:2181"  
  kafka:  
   image: wurstmeister/kafka  
    ports:  
      - "9092:9092"  
    environment:  
     KAFKA_ADVERTISED_HOST_NAME: localhost  
     KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181  
     KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"  
    volumes:  
     - /var/run/docker.sock:/var/run/docker.sock
</code></pre></div></div>
<p>The above compose file defines two services: <code class="language-plaintext highlighter-rouge">zookeeper</code> and <code class="language-plaintext highlighter-rouge">kafka</code>. The <code class="language-plaintext highlighter-rouge">zookeeper</code> service uses a public <code class="language-plaintext highlighter-rouge">zookeeper</code> image and he <code class="language-plaintext highlighter-rouge">kafka</code> service uses a public <code class="language-plaintext highlighter-rouge">kafka</code> image pulled from the Docker Hub registry.</p>

<p><strong>1. Start the Kafka service</strong></p>

<p>Open a terminal, go to the directory where you have the <code class="language-plaintext highlighter-rouge">docker-compose.yml</code> file, and execute the following command. This command starts the docker-compose engine, and downloads the images and runs them.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$docker compose up -d  
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[+] Running 3/3
 ⠿ Network "kafka_default"      Created			4.1s
 ⠿ Container kafka_kafka_1      Started			4.6s
 ⠿ Container kafka_zookeeper_1  Started			5.5s 
</code></pre></div></div>

<p>To list all running docker containers, run the following command</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$docker compose ps  
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME                SERVICE             STATUS              PORTS
kafka_kafka_1       kafka               running             0.0.0.0:9092-&gt;9092/tcp
kafka_zookeeper_1   zookeeper           running             0.0.0.0:2181-&gt;2181/tcp, 22/tcp, 2888/tcp, 3888/tcp  
</code></pre></div></div>

<p>You can shut down docker-compose by executing the following command in another terminal.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$docker compose down  
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[+] Running 3/3
 ⠿ Container kafka_kafka_1      Removed			6.0s
 ⠿ Container kafka_zookeeper_1  Removed			11.2s
 ⠿ Network "kafka_default"      Removed			2.7s    
</code></pre></div></div>

<p>Start the kafka service and check the ZooKeeper logs to verify that ZooKeeper is working and healthy.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$docker compose logs zookeeper | grep -i binding  

zookeeper_1  | 2021-08-30 16:11:37,821 [myid:] - INFO  [main:NIOServerCnxnFactory@89] - binding to port 0.0.0.0/0.0.0.0:2181
</code></pre></div></div>

<p>Next, check the Kafka logs to verify that broker is working and healthy.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$docker compose logs kafka | grep -i started  

kafka_1  | [2021-08-30 16:11:43,780] INFO [SocketServer brokerId=1001] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
kafka_1  | [2021-08-30 16:11:44,493] INFO [SocketServer brokerId=1001] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
kafka_1  | [2021-08-30 16:11:44,518] INFO [KafkaServer id=1001] started (kafka.server.KafkaServer)
</code></pre></div></div>

<p>Two fundamental concepts in Kafka are Topics and Partitions. Kafka topics are divided into a number of partitions. While the topic is a logical concept in Kafka, a partition is the smallest storage unit that holds a subset of records owned by a topic. Each partition is a single log file where records are written to it in an append-only fashion.</p>

<p><strong>2. Create a Kafka topic</strong></p>

<p>The Kafka cluster stores streams of records in categories called topics. Each record in a topic consists of a key, a value, and a timestamp. A topic can have zero, one, or many consumers that subscribe to the data written to it.</p>

<p>Use <code class="language-plaintext highlighter-rouge">docker compose exec</code> to execute a command in a running container. For example, <code class="language-plaintext highlighter-rouge">docker compose exec</code> command by default allocates a TTY, so that you can use such a command to get an interactive prompt. Go into directory where <code class="language-plaintext highlighter-rouge">docker-compose.yml</code> file present, and execute it as</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$docker compose exec kafka bash  
</code></pre></div></div>

<p>(for zookeeper <code class="language-plaintext highlighter-rouge">$docker compose exec zookeeper bash</code>)</p>

<p>Change the directory to /opt/kafka/bin where you find scripts such as <code class="language-plaintext highlighter-rouge">kafka-topics.sh</code>.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cd /opt/kafka/bin
</code></pre></div></div>

<p><strong>Create a new topic or, list or delete existing topics</strong>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bash-4.4# ./kafka-topics.sh \  
 --create \  
 --topic mytopic \  
 --partitions 1 \  
 --replication-factor 1 \  
 --bootstrap-server localhost:9092  
</code></pre></div></div>

<p><b>Figure 1</b>. Kafka topic partitions layout (Image source <a href="https://cloudblogs.microsoft.com/opensource/2018/07/09/how-to-data-processing-apache-kafka-spark/">cloudblogs.microsoft.com</a>).</p>

<p>Kafka topics are divided into a number of partitions.  Each partition in a topic is an ordered, immutable sequence of records that continually appended.<br />
<img src="/images/kafka-partitions-combined.png" alt="Partitions" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bash-4.4# ./kafka-topics.sh --list --bootstrap-server localhost:9092  
</code></pre></div></div>

<p>If necessary, delete a topic using the following command.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bash-4.4# ./kafka-topics.sh --delete --topic mytopic --bootstrap-server localhost:9092  
</code></pre></div></div>

<p><strong>3. How to produce and consume messages from kafka Topic using using the command line?</strong></p>

<p>Kafka producers are those client applications that publish (write) events to Kafka, and Kafka consumers are those that subscribe to (read and process) these events. A producer can use a partition key to direct messages to a specific partition. If a producer doesn’t specify a partition key when producing a record, Kafka will use a round-robin partition assignment.</p>

<p><b>Figure 2</b>. Relationship between kafka components (Image source <a href="https://medium.com/@kavimaluskam/start-your-real-time-pipeline-with-apache-kafka-39e30129892a">https://medium.com</a>).</p>

<p><img src="/images/kafka-producer-consumer.png" alt="Producer" /></p>

<p>Kafka broker (a.k.a Kafka server/node) is the server node in the cluster, mainly responsible for hosting partitions of Kafka topics, transferring messages from Kafka producer to Kafka consumer and, providing data replication and partitioning within a Kafka Cluster.</p>

<p>The following is a producer command line to read data from standard input and write it to a Kafka topic.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bash-4.4# ./kafka-console-producer.sh \
 --broker-list localhost:9092 \
 --topic mytopic
  
&gt;Hello  
&gt;World  
^C
</code></pre></div></div>

<p>The following is a command line to read data from a Kafka topic and write it to standard output.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bash-4.4# ./kafka-console-consumer.sh \
 --bootstrap-server localhost:9092 \
 --topic mytopic \
 --from-beginning
  
Hello  
World  
^CProcessed a total of 2 messages  
</code></pre></div></div>

<p><strong>4. How to consume messages from kafka Topic using java web application?</strong></p>

<p>Another way of reading data from a Kafka topic is by simply using a <em>Java Spring Boot</em>.</p>

<p>The following demonstrates how to receive messages from Kafka topic. First in this blog I create a Spring Kafka Consumer, which is able to listen the messages sent to a Kafka topic using the above commandline. Then I create a Spring Kafka Producer, which is able to send messages to a Kafka topic.</p>

<p><b>Figure 3</b>. Kafka Producer and Consumer in Java (Source <a href="https://blog.clairvoyantsoft.com/benchmarking-kafka-e7b7c289257d">blog.clairvoyantsoft.com</a>).</p>

<p><img src="/images/kafka-producer-consumer-java.png" alt="Java" /></p>

<p>Download <a href="https://spring.io/tools">Spring Tool Suite4</a> and install it.  <br />
At Eclipse IDE’s Package Explorer click “Create new Spring Starter Project” and<br />
Name: SpringBootKafka<br />
Type: Maven project<br />
Spring Boot Version: 2.5.4<br />
Java Version: 8
Search “kafka” at New Spring Starter Project Dependencies and select “Spring for Apache Kafka“<br />
Click Finish.</p>

<p>The Spring Initializr creates the following simple application class for you.</p>

<p><code class="language-plaintext highlighter-rouge">SpringBootKafkaApplication.java</code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@SpringBootApplication  
public class SpringBootKafkaApplication {  
 public static void main(String[] args) {  
  SpringApplication.run(SpringBootApplication.class, args);  
 }  
}  
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">@SpringBootApplication</code> annotation is equivalent to using <code class="language-plaintext highlighter-rouge">@Configuration</code>, <code class="language-plaintext highlighter-rouge">@EnableAutoConfiguration</code>, and <code class="language-plaintext highlighter-rouge">@ComponentScan</code>. As a result, when we run this Spring Boot application, it will automatically scan the components in the current package and its sub-packages. Thus it will register them in Spring’s Application Context, and allow us to inject beans using <code class="language-plaintext highlighter-rouge">@Autowired</code>.</p>

<p><strong>Configure Kafka through application.yml configuration file</strong></p>

<p>In Spring Boot, properties are kept in the <code class="language-plaintext highlighter-rouge">application.properties</code> file under the classpath. 
The <code class="language-plaintext highlighter-rouge">application.properties</code> file is located in the <code class="language-plaintext highlighter-rouge">src/main/resources</code> directory. 
Change <code class="language-plaintext highlighter-rouge">application.properties</code> file to <code class="language-plaintext highlighter-rouge">application.yml</code>, then add the following content.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>spring:  
  kafka:  
   consumer:  
    bootstrap-servers: localhost:9092  
    group-id: group_test1  
    auto-offset-reset: earliest  
    key-deserializer: org.apache.kafka.common.serialization.StringDeserializer  
    value-deserializer: org.apache.kafka.common.serialization.StringDeserializer  
</code></pre></div></div>

<p><strong>Create a Spring Kafka Consumer class</strong></p>

<p>Create a class called <code class="language-plaintext highlighter-rouge">KafkaConsumer.java</code> and add a method with the @KakfaListener annotation.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Service;
 
@Service  
public class KafkaConsumer {  
 @KafkaListener(id = "group_test1", topics = "mytopic")  
 public void consumeMessage(String message) {  
  System.out.println("Consumed message: " + message);  
 }  
}
</code></pre></div></div>

<p>In most typical Spring Framework applications, we have distinct layers like data access, presentation, service, business, etc.</p>

<p><code class="language-plaintext highlighter-rouge">@Component</code> allows us to auto-detect implementation classes through the classpath scanning.<br />
<code class="language-plaintext highlighter-rouge">@Service</code> annotates classes at the service layer.<br />
<code class="language-plaintext highlighter-rouge">@Repository</code> annotates classes at the persistence layer, which will act as a database repository.</p>

<p><em>How to run Spring Boot web application in Eclipse?</em></p>

<p>In eclipse Project Explorer, right click the project name -&gt; select “Run As” -&gt; “Maven Build…”<br />
In the goals, enter <code class="language-plaintext highlighter-rouge">spring-boot:run</code><br />
then click Run button.</p>

<p>If you have Spring Tool Suite (STS) plug-in, you see a “Spring Boot App” option under Run As.</p>

<p>Run the following console producer which will enable you to send messages to Kafka:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bash-4.4# ./kafka-console-producer.sh \
 --broker-list localhost:9092 \
 --topic mytopic
  
&gt;Hello  
&gt;World  
^C  
</code></pre></div></div>

<p>Try sending a few messages like above (Hello, World etc) and watch the application standard output in the Eclipse shell where you are running your Spring Boot application.</p>

<p>Eclipse Console:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::                (v2.5.4)

...
...
...

Consumed message: Hello
Consumed message: World 
</code></pre></div></div>

<p><strong>5. How to produce and consume messages from Kafka Topic using java web application?</strong></p>

<p>The above <code class="language-plaintext highlighter-rouge">KafkaConsumer.java</code> receives messages that were sent to a Kafka Topic (like consumer command line).<br />
The followng <code class="language-plaintext highlighter-rouge">KafkaProducer.java</code> send messages to a Kafka Topic (like producer command line).</p>

<p>Make sure to have spring-web dependency in <code class="language-plaintext highlighter-rouge">pom.xml</code> file.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;dependency&gt;  
  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;  
  &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;  
&lt;/dependency&gt;  
</code></pre></div></div>

<p>Update <code class="language-plaintext highlighter-rouge">application.yml</code> file.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>server:
  port: 8080
spring:
  kafka:
   consumer:
    bootstrap-servers: localhost:9092
    group-id: group_test1
    auto-offset-reset: earliest
    key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    value-deserializer: org.apache.kafka.common.serialization.StringDeserializer  
   producer:  
    bootstrap-servers: localhost:9092  
    key-serializer: org.apache.kafka.common.serialization.StringSerializer  
    value-serializer: org.apache.kafka.common.serialization.StringSerializer  
</code></pre></div></div>

<p>Add two new java classes <code class="language-plaintext highlighter-rouge">KafkaProducer.java</code> and <code class="language-plaintext highlighter-rouge">KafkaController.java</code></p>

<p><code class="language-plaintext highlighter-rouge">KafkaProducer.java</code> class</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Service;

@Service  
public class KafkaProducer {  
 private static final String TOPIC = "mytopic";  
 @Autowired  
 private KafkaTemplate&lt;String, String&gt; kafkaTemplate;  
 public void sendMessage(String message) {  
  kafkaTemplate.send(TOPIC, message);  
  System.out.println("Produced message: " + message);  
 }  
}   
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">KafkaController.java</code> class</p>

<p>We typically use <code class="language-plaintext highlighter-rouge">@Controller</code> in combination with a <code class="language-plaintext highlighter-rouge">@RequestMapping</code> annotation for request handling methods. <code class="language-plaintext highlighter-rouge">@RestController</code> is a specialized version of the controller. It includes the <code class="language-plaintext highlighter-rouge">@Controller</code> and <code class="language-plaintext highlighter-rouge">@ResponseBody</code> annotations, and as a result, simplifies the controller implementation.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.RestController;

@RestController  
@RequestMapping(value="/kafka")  
public class KafkaController {  

 private final KafkaProducer producer;  

 @Autowired  
 KafkaController(KafkaProducer producer){  
  this.producer = producer;  
 }  

@PostMapping(value="/publish")  
 public void messagePrint(@RequestParam(value="message", required = false) String message) {  
  this.producer.sendMessage(message);  
 }  
}  
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">@GetMapping</code> is specialized version of <code class="language-plaintext highlighter-rouge">@RequestMapping</code> annotation that acts as a shortcut for <code class="language-plaintext highlighter-rouge">@RequestMapping(method = RequestMethod.GET)</code>.<br />
<code class="language-plaintext highlighter-rouge">@PostMapping</code> is specialized version of <code class="language-plaintext highlighter-rouge">@RequestMapping</code> annotation that acts as a shortcut for <code class="language-plaintext highlighter-rouge">@RequestMapping(method = RequestMethod.POST)</code>.</p>

<p>Behind the scenes, spring looks for a query string parameter <code class="language-plaintext highlighter-rouge">message</code> and extracts its value from the request. Then it invokes the request handler messagePrint(message) and passes the param value as an argument.</p>

<p><strong>6. Run Spring Boot Web application and test the controller</strong> by executing a <code class="language-plaintext highlighter-rouge">POST</code> kafka/publish request and pass a query string parameter – message.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl --request POST "http://localhost:8080/kafka/publish?message='hello'"
</code></pre></div></div>

<p>OR make <code class="language-plaintext highlighter-rouge">POST</code> request using <a href="https://www.getpostman.com">Postman</a>.</p>

<p>Select <code class="language-plaintext highlighter-rouge">POST</code> and use the API <code class="language-plaintext highlighter-rouge">http://localhost:8080/kafka/publish</code><br />
<strong>Body</strong>: form-data  <strong>KEY</strong>: message  <strong>VALUE</strong>: hello</p>

<p>Finally click <strong>send</strong>.</p>

<p>See Eclipse Console for messages:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...  
...  
...  
2021-08-30 17:34:14.022  INFO 3851 --- [nio-8080-exec-2] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.7.1
2021-08-30 17:34:14.023  INFO 3851 --- [nio-8080-exec-2] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 61dbce85d0d41457
2021-08-30 17:34:14.023  INFO 3851 --- [nio-8080-exec-2] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1630359254022
2021-08-30 17:34:14.033  INFO 3851 --- [ad | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: mzjgWnhAS5GIknFkngu7qw

Produced message: hello  
Consumed message: hello
</code></pre></div></div>

<p>You can shut down docker-compose by executing the following command in another terminal.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bash-4.4# exit  

$docker compose down  
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[+] Running 3/3
 ⠿ Container kafka_kafka_1      Removed                                                                                                                    5.2s
 ⠿ Container kafka_zookeeper_1  Removed                                                                                                                   11.2s
 ⠿ Network "kafka_default"      Removed    
</code></pre></div></div>

<p>Further reading…</p>

<p><a href="https://dattell.com/data-architecture-blog/what-is-zookeeper-how-does-it-support-kafka/">What is ZooKeeper &amp; How Does it Support Kafka?</a><br />
<a href="https://medium.com/event-driven-utopia/understanding-kafka-topic-partitions-ae40f80552e8">Understanding Kafka Topic Partitions</a><br />
<a href="https://www.instaclustr.com/the-power-of-kafka-partitions-how-to-get-the-most-out-of-your-kafka-cluster/">The Power of Kafka Partitions : How to Get the Most out of Your Kafka Cluster?</a></p>

        
      </section>

      <footer class="page__meta">
        
        


  




  
  
  

  <p class="page__taxonomy">
    <strong><i class="fa fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="https://adinasarapu.github.io/tags/#apache-kafka" class="page__taxonomy-item" rel="tag">apache kafka</a><span class="sep">, </span>
    
      
      
      <a href="https://adinasarapu.github.io/tags/#big-data" class="page__taxonomy-item" rel="tag">big data</a><span class="sep">, </span>
    
      
      
      <a href="https://adinasarapu.github.io/tags/#bioinformatics" class="page__taxonomy-item" rel="tag">Bioinformatics</a><span class="sep">, </span>
    
      
      
      <a href="https://adinasarapu.github.io/tags/#docker" class="page__taxonomy-item" rel="tag">docker</a><span class="sep">, </span>
    
      
      
      <a href="https://adinasarapu.github.io/tags/#emory-university" class="page__taxonomy-item" rel="tag">Emory University</a><span class="sep">, </span>
    
      
      
      <a href="https://adinasarapu.github.io/tags/#java" class="page__taxonomy-item" rel="tag">Java</a><span class="sep">, </span>
    
      
      
      <a href="https://adinasarapu.github.io/tags/#real-time-data-pipeline" class="page__taxonomy-item" rel="tag">real time data pipeline</a><span class="sep">, </span>
    
      
      
      <a href="https://adinasarapu.github.io/tags/#restful-services" class="page__taxonomy-item" rel="tag">RESTful services</a><span class="sep">, </span>
    
      
      
      <a href="https://adinasarapu.github.io/tags/#spring-boot" class="page__taxonomy-item" rel="tag">Spring Boot</a><span class="sep">, </span>
    
      
      
      <a href="https://adinasarapu.github.io/tags/#yaml" class="page__taxonomy-item" rel="tag">YAML</a><span class="sep">, </span>
    
      
      
      <a href="https://adinasarapu.github.io/tags/#zookeeper" class="page__taxonomy-item" rel="tag">Zookeeper</a>
    
    </span>
  </p>




      </footer>

      

<section class="page__share">
  
    <h4 class="page__share-title">Share on</h4>
  

  <a href="https://twitter.com/intent/tweet?text=https://adinasarapu.github.io/posts/2020/01/blog-post-kafka/" class="btn btn--twitter" title="Share on Twitter"><i class="fab fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https://adinasarapu.github.io/posts/2020/01/blog-post-kafka/" class="btn btn--facebook" title="Share on Facebook"><i class="fab fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://adinasarapu.github.io/posts/2020/01/blog-post-kafka/" class="btn btn--linkedin" title="Share on LinkedIn"><i class="fab fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>

      


  <nav class="pagination">
    
      <a href="#" class="pagination--pager disabled">Previous</a>
    
    
      <a href="https://adinasarapu.github.io/big-data/2020/02/blog-post-spark/" class="pagination--pager" title="Building a real-time big data pipeline (2: Spark Core, Hadoop, Scala)
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
</div>


    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->
<!--<a href="/cv/">Resume</a> -->
<!-- end custom footer snippets -->

        

<div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
    
    
      <li><a href="http://github.com/adinasarapu"><i class="fab fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
      <li><a href="http://bitbucket.org/adinasarapu"><i class="fab fa-bitbucket" aria-hidden="true"></i> Bitbucket</a></li>
    
    <!--<li><a href="https://adinasarapu.github.io/feed.xml">
	<i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>-->
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2023 Ashok R. Dinasarapu. 101 Woodruff Circle, Woodruff Memorial Research Building,  Room#6302, Emory University, Atlanta, GA 30322.</div>

      </footer>
    </div>

    <script src="https://adinasarapu.github.io/assets/js/main.min.js"></script>




  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'G-RWM39QLMPF', 'auto');
  ga('send', 'pageview');
</script>






  </body>
</html>

