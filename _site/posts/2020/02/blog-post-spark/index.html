

<!doctype html>
<html lang="en" class="no-js">
  <head>
    

<meta charset="utf-8">



<!-- begin SEO -->









<title>Building a real-time big data pipeline (part 2: Spark, Hadoop) - Ashok R. Dinasarapu</title>







<meta property="og:locale" content="en-US">
<meta property="og:site_name" content="Ashok R. Dinasarapu">
<meta property="og:title" content="Building a real-time big data pipeline (part 2: Spark, Hadoop)">


  <link rel="canonical" href="http://localhost:4000/posts/2020/02/blog-post-spark/">
  <meta property="og:url" content="http://localhost:4000/posts/2020/02/blog-post-spark/">



  <meta property="og:description" content="Apache Spark1 is a unified analytics engine for large-scale data processing.            Apache Spark&nbsp;&#8617;      ">





  

  





  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2020-02-09T00:00:00-08:00">








  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Ashok R. Dinasarapu",
      "url" : "http://localhost:4000",
      "sameAs" : null
    }
  </script>






<!-- end SEO -->


<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Ashok R. Dinasarapu Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">

<meta http-equiv="cleartype" content="on">
    

<!-- start custom head snippets -->

<link rel="apple-touch-icon" sizes="57x57" href="http://localhost:4000/images/apple-touch-icon-57x57.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="60x60" href="http://localhost:4000/images/apple-touch-icon-60x60.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="76x76" href="http://localhost:4000/images/apple-touch-icon-76x76.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="114x114" href="http://localhost:4000/images/apple-touch-icon-114x114.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="120x120" href="http://localhost:4000/images/apple-touch-icon-120x120.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="144x144" href="http://localhost:4000/images/apple-touch-icon-144x144.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="152x152" href="http://localhost:4000/images/apple-touch-icon-152x152.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="180x180" href="http://localhost:4000/images/apple-touch-icon-180x180.png?v=M44lzPylqQ">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-32x32.png?v=M44lzPylqQ" sizes="32x32">
<link rel="icon" type="image/png" href="http://localhost:4000/images/android-chrome-192x192.png?v=M44lzPylqQ" sizes="192x192">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-96x96.png?v=M44lzPylqQ" sizes="96x96">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-16x16.png?v=M44lzPylqQ" sizes="16x16">
<link rel="manifest" href="http://localhost:4000/images/manifest.json?v=M44lzPylqQ">
<link rel="mask-icon" href="http://localhost:4000/images/safari-pinned-tab.svg?v=M44lzPylqQ" color="#000000">
<link rel="shortcut icon" href="/images/favicon.ico?v=M44lzPylqQ">
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-TileImage" content="http://localhost:4000/images/mstile-144x144.png?v=M44lzPylqQ">
<meta name="msapplication-config" content="http://localhost:4000/images/browserconfig.xml?v=M44lzPylqQ">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="http://localhost:4000/assets/css/academicons.css"/>
<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg"><a href="http://localhost:4000/">Ashok R. Dinasarapu</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/publications/">Publications</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/teaching/">Teaching</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/year-archive/">NGS Pipelines</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/cv/">Résumé</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/talks/">Talks</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    





<div id="main" role="main">
  


  <div class="sidebar sticky">
  



<div itemscope itemtype="http://schema.org/Person">

  <div class="author__avatar">
    
    	<img src="http://localhost:4000/images/profile.png" class="author__avatar" alt="Scientist, Bioinformatics">
    
  </div>

  <div class="author__content">
    <h3 class="author__name">Scientist, Bioinformatics</h3>
    <p class="author__bio">Emory University</p>
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> Atlanta, GA</li>
      
      
      
      
        <li><a href="mailto:ashok.reddy.dinasarapu@emory.edu"><i class="fa fa-fw fa-envelope-square" aria-hidden="true"></i> Email</a></li>
      
      
      
        <li><a href="https://twitter.com/adinasarapu"><i class="fa fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
      
      
      
      
        <li><a href="https://www.linkedin.com/in/dareddy"><i class="fa fa-fw fa-linkedin-square" aria-hidden="true"></i> LinkedIn</a></li>
      
      
      
      
      
        <li><a href="https://bitbucket.org/adinasarapu"><i class="fa fa-fw fa-bitbucket" aria-hidden="true"></i> Bitbucket</a></li>
      
      
        <li><a href="https://github.com/adinasarapu"><i class="fa fa-fw fa-github" aria-hidden="true"></i> Github</a></li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
        <li><a href="https://scholar.google.com/citations?user=b6GBykAAAAAJ"><i class="ai ai-google-scholar-square ai-fw"></i> Google Scholar</a></li>
      
      
        <li><a href="http://orcid.org/0000-0002-1423-1518"><i class="ai ai-orcid-square ai-fw"></i> ORCID</a></li>
      
      
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="Building a real-time big data pipeline (part 2: Spark, Hadoop)">
    <meta itemprop="description" content="Apache Spark1 is a unified analytics engine for large-scale data processing.            Apache Spark&nbsp;&#8617;      ">
    <meta itemprop="datePublished" content="February 09, 2020">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 class="page__title" itemprop="headline">Building a real-time big data pipeline (part 2: Spark, Hadoop)
</h1>
          
            <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 


  
	  7 minute read
	
</p>
          
        
        
        
          <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2020-02-09T00:00:00-08:00">February 09, 2020</time></p>
        
        
             
        
    
        </header>
      

      <section class="page__content" itemprop="text">
        <p>Apache Spark<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup> is a unified analytics engine for large-scale data processing.</p>

<p><strong>What exactly is Apache Spark?</strong></p>

<p>A Cluster computing engine and a set of libraries, application programming interfaces (APIs) together make apache spark. The spark core itself has two parts. 1. Computing engine and 2. Spark Core APIs (Scala, Java, Python and R).</p>

<p><strong>Apache Spark Ecosystem</strong></p>
<div class="highlighter-rouge"><pre class="highlight"><code>+--------+-----------+-------+----------+
| SQL	 | Streaming | MLlib |	GraphX 	|
|---------------------------------------|
|	Spark Core API			|	
|---------------------------------------|
| Scala	| Python    |	Java |	R	|
|---------------------------------------|	
|	Compute Engine			|
+---------------------------------------+
</code></pre>
</div>
<p><strong>Computing Engine</strong><br />
Apache Hadoop<sup id="fnref:2"><a href="#fn:2" class="footnote">2</a></sup> offers distributed storage (HDFS), resource manager (YARN)  and computing framework (Map Reduce). Apache Spark is a distributed processing engine but it doesn’t come with inbuilt cluster resource manager and distributed storage system. We have to plugin a cluster manager and a storage system of our choice. We can use YARN, Mesos, and Kubernetes as a cluster manager for Apache Spark. Similarly, for the storage system we can use HDFS, Amazon S3, Google cloud storage or Cassandra File System (CFS) and more. The compute engine provides some basic functionality like memory management, task scheduling, fault recovery and most importantly interacting with the cluster manager and storage system.</p>

<p><strong>Core APIs</strong>
Spark core consists of structured API and unstructured API. Structured API consists of Data Frames and Data Sets. Unstructured APIs consists of RDDs, accumulators and broadcast variables<sup id="fnref:3"><a href="#fn:3" class="footnote">3</a></sup>. These core APIs are available as Scala, Java, Python and R.  <br />
Outside of Spark Core we have 4 sets of libraries and packages, Spark SQL, Spark Streaming, MLlib and Graphx. They directly depend on Spark Core APIs to achieve distributed processing.</p>

<p>Typical Spark Application Process Flow: Apache Spark reads some data from source and load it into a Spark. There are 3 alternatives to hold data in Spark. 1) Data Frame 2) Data Set and 3) RDD. Latest Spark release recommended to use Data Frame and Data Set. Both of them are compiled down in RDD.</p>

<p><strong>RDD: Resilient Distributed Data Set</strong> <sup id="fnref:3:1"><a href="#fn:3" class="footnote">3</a></sup> Spark RDD is a resilient, partitioned, distributed and immutable collection of data.<br />
<strong>Resilient</strong> – RDDs are fault tolerant.<br />
<strong>Partitioned</strong> – Spark breaks the RDD into smaller chunks of data. These pieces are called partitions.<br />
<strong>Distributed</strong> – Instead of keeping these partitions on a single machine, Spark spreads them across the cluster.<br />
<strong>Immutable</strong> – Once defined, you can’t change them. So Spark RDD is a read-only data structure.</p>

<p>For RDDs vs DataFrames and Datasets - When to use them and why. Read <sup id="fnref:4"><a href="#fn:4" class="footnote">4</a></sup>.</p>

<p>We can create RDD using two methods. 1.Load some data from a source or 2. Create an RDD by transforming another RDD</p>

<p><strong>Step 1</strong>: Hadoop installation</p>

<p>See tutorial on <a href="https://www.quickprogrammingtips.com/big-data/how-to-install-hadoop-on-mac-os-x-el-capitan.html">How to Install and Configure Hadoop on Mac</a></p>

<p>Update your <code class="highlighter-rouge">~/.bash_profile</code> file, which is a configuration file for configuring user environments.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>$vi ~/.bash_profile  
export HADOOP_HOME=/Users/adinasarapu/Documents/hadoop-3.1.3  
export PATH=$PATH:$HADOOP_HOME/bin  
</code></pre>
</div>

<p><strong>Start Hadoop</strong></p>

<div class="highlighter-rouge"><pre class="highlight"><code>$bash sbin/start-dfs.sh 
Starting namenodes on [localhost]
Starting datanodes
Starting secondary namenodes [Ashoks-MacBook-Pro.local]
</code></pre>
</div>

<p><strong>Verify Hadoop installation</strong></p>
<div class="highlighter-rouge"><pre class="highlight"><code>$ jps
61073 ResourceManager
82025 SecondaryNameNode
61177 NodeManager
81882 DataNode
82303 Jps
81774 NameNode
</code></pre>
</div>

<p><strong>Create user</strong></p>

<p><code class="highlighter-rouge">$hadoop fs -mkdir -p /user/adinasarapu</code></p>

<p><strong>Move file to HDFS</strong></p>

<p><code class="highlighter-rouge">$hadoop fs -copyFromLocal samples.csv /user/adinasarapu</code></p>

<p>Now the data file is at real distributed storage. The file location at HDFS is <code class="highlighter-rouge">hdfs://localhost:9000/user/adinasarapu/ samples.csv</code></p>

<p><strong>List files moved</strong><br />
<code class="highlighter-rouge">$ hadoop fs -ls /user/adinasarapu</code></p>
<div class="highlighter-rouge"><pre class="highlight"><code>Found 3 items
-rw-r--r--   1 adinasarapu supergroup  110252495 2020-02-08 17:04 /user/adinasarapu/flist.txt
-rw-r--r--   1 adinasarapu supergroup       1318 2020-02-09 14:47 /user/adinasarapu/samples.csv
-rw-r--r--   1 adinasarapu supergroup     303684 2020-02-09 08:21 /user/adinasarapu/survey.csv
</code></pre>
</div>

<p><strong>Apache Spark installation</strong></p>

<p>See tutorial on <a href="https://medium.com/luckspark/installing-spark-2-3-0-on-macos-high-sierra-276a127b8b85">Installing Apache Spark … on macOS</a><br />
Update your <code class="highlighter-rouge">~/.bash_profile</code> file, which is a configuration file for configuring user environments.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>$vi ~/.bash_profile  
export SPARK_HOME=/Users/adinasarapu/Documents/spark-3.0.0-preview2-bin-hadoop3.2  
export PATH=$PATH:$SPARK_HOME/bin  
</code></pre>
</div>

<p><strong>Start Spark shell</strong></p>
<div class="highlighter-rouge"><pre class="highlight"><code>$spark-shell  
20/02/09 15:03:23 ..  
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties  
Setting default log level to "WARN".  
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).  
Spark context Web UI available at http://192.168.0.5:4040  
Spark context available as 'sc' (master = local[*], app id = local-1581278612106).  
Spark session available as 'spark'.  
Welcome to  
      ____              __  
     / __/__  ___ _____/ /__  
    _\ \/ _ \/ _ `/ __/  '_/  
   /___/ .__/\_,_/_/ /_/\_\   version 3.0.0-preview2  
      /_/  
           
Using Scala version 2.12.10 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_102)  
Type in expressions to have them evaluated.  
Type :help for more information.  
</code></pre>
</div>

<p><strong>Read CSV data</strong></p>
<div class="highlighter-rouge"><pre class="highlight"><code>scala&gt; val df = spark.read.options(Map(  
	"header" -&gt; "true",  
	"inferSchema"-&gt;"true",  
	"nullValue"-&gt;"NA",  
	"timestampFormat"-&gt;"MM-dd-yyyy",  
	"mode"-&gt;"failfast")).csv("hdfs://localhost:9000/user/adinasarapu/samples.csv")  

df: org.apache.spark.sql.DataFrame = [Sample: string, p16: string ... 7 more fields]
</code></pre>
</div>

<p><strong>Check the number of partitions</strong></p>
<div class="highlighter-rouge"><pre class="highlight"><code>scala&gt; df.rdd.getNumPartitions  
res4: Int = 1  
</code></pre>
</div>

<p><strong>Set/increase Number of partitions to 3</strong></p>
<div class="highlighter-rouge"><pre class="highlight"><code>scala&gt; val df2 = df.repartition(3).toDF  
df2: org.apache.spark.sql.DataFrame = [Sample: string, p16: string ... 7 more fields]  
</code></pre>
</div>
<p><strong>Recheck the number of partitions</strong></p>
<div class="highlighter-rouge"><pre class="highlight"><code>scala&gt; df2.rdd.getNumPartitions  
res5: Int = 3  
</code></pre>
</div>

<p><strong>SQL like operation</strong> <br />
Data Frame follows row and column structure like a database table. Data Frame compiles down to RDDs. RDDs are immutable and once loaded you can’t modify it. However, you can perform the following operations a) Transformation and b) Actions. Spark Data Frames carries the same legacy from RDDs. Like RDDs, Spark Data Frames are immutable. You can perform transformation and actions on Data Frames.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>scala&gt; df.select("Sample","Age","Sex","Anatomy").filter("Age &lt; 55").show  
  
+------+---+------+-------+  
|Sample|Age|   Sex|Anatomy|  
+------+---+------+-------+  
|GHN-57| 50|female|    BOT|  
|GHN-39| 51|  male|    BOT|  
|GHN-60| 41|  male|    BOT|  
|GHN-64| 49|  male|    BOT|  
|GHN-77| 53|  male|    BOT|  
|GHN-66| 52|  male| Tonsil|  
|GHN-67| 54|  male| Tonsil|  
|GHN-68| 51|  male| Tonsil|  
|GHN-80| 54|  male| Tonsil|  
|GHN-83| 54|  male| Tonsil|  
+------+---+------+-------+
</code></pre>
</div>
<div class="highlighter-rouge"><pre class="highlight"><code>scala&gt; val df1 = df.select($"Sex",$"Radiation")  
df1: org.apache.spark.sql.DataFrame = [Sex: string, Radiation: string]  

scala&gt; df1.show  
+------+---------+  
|   Sex|Radiation|  
+------+---------+  
|female|        Y|  
|female|        Y|  
|  male|        Y|  
|  male|        N|  
|  male|        Y|  
|  male|        Y|  
|  male|        Y|  
|  male|        Y|  
|  male|        Y|  
|  male|        Y|  
|  male|        N|  
|  male|        N|  
|  male|  Unknown|  
|  male|        Y|  
|female|        Y|  
|  male|        Y|  
|  male|        Y|  
|  male|        Y|  
|  male|        Y|  
|  male|        N|  
+------+---------+  
only showing top 20 rows  
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>scala&gt; val df2 = df1.select($"Sex",   
		(when($"Radiation" === "Y",1).otherwise(0)).alias("All-Yes"),  
		(when($"Radiation" === "N",1).otherwise(0)).alias("All-Nos"),  
		(when($"Radiation" === "Unknown",1).otherwise(0)).alias("All-Unknown"))  
df2: org.apache.spark.sql.DataFrame = [Sex: string, All-Yes: int ... 2 more fields]  

scala&gt; df2.show  
+------+-------+-------+-----------+  
|   Sex|All-Yes|All-Nos|All-Unknown|  
+------+-------+-------+-----------+  
|female|      1|      0|          0|  
|female|      1|      0|          0|  
|  male|      1|      0|          0|  
|  male|      0|      1|          0|  
|  male|      1|      0|          0|  
|  male|      1|      0|          0|  
|  male|      1|      0|          0|  
|  male|      1|      0|          0|  
|  male|      1|      0|          0|  
|  male|      1|      0|          0|  
|  male|      0|      1|          0|  
|  male|      0|      1|          0|  
|  male|      0|      0|          1|  
|  male|      1|      0|          0|  
|female|      1|      0|          0|  
|  male|      1|      0|          0|  
|  male|      1|      0|          0|  
|  male|      1|      0|          0|  
|  male|      1|      0|          0|  
|  male|      0|      1|          0|  
+------+-------+-------+-----------+  
only showing top 20 rows  
</code></pre>
</div>

<p><strong>Scala user-defined function (UDF)</strong></p>

<div class="highlighter-rouge"><pre class="highlight"><code>def parseSex(g: String) = {  
 	g.toLowerCase match {   
			case "male"  =&gt; “Male”  
			case "female" =&gt; “Female”   
			case _ =&gt; “Other”  
	}  
}   

scala&gt; val parseSexUDF = udf(parseSex _)  

parseGenderUDF: org.apache.spark.sql.expressions.UserDefinedFunction = SparkUserDefinedFunction($Lambda$3628/1633612848@4ee80d4c,StringType,List(Some(Schema(StringType,true))),None,true,true)  
</code></pre>
</div>
<div class="highlighter-rouge"><pre class="highlight"><code>scala&gt; val df3 = df2.select((parseSexUDF($"Sex")).alias("Sex"),$"All-Yes",$"All-Nos",$"All-Unknown")  
df3: org.apache.spark.sql.DataFrame = [Sex: string, All-Yes: int ... 2 more fields]  
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>scala&gt; val df4 = df3.groupBy("Sex").agg(sum($"All-Yes"), sum($"All-Nos"), sum($"All-Unknown"))  
df4: org.apache.spark.sql.DataFrame = [Sex: string, sum(All-Yes): bigint ... 2 more fields]  

scala&gt; df4.show  
+------+------------+------------+----------------+  
|   Sex|sum(All-Yes)|sum(All-Nos)|sum(All-Unknown)|  
+------+------------+------------+----------------+  
|Female|           3|           0|               0|  
|  Male|          18|           5|               1|  
+------+------------+------------+----------------+  
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>scala&gt; val df5 = df4.filter($"Sex" =!= "Unknown")  
df5: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Sex: string, sum(All-Yes): bigint ... 2 more fields]  
  
scala&gt; df5.collect()  
res22: Array[org.apache.spark.sql.Row] = Array([Male,18,5,1])  

scala&gt; df5.show  
+----+------------+------------+----------------+  
| Sex|sum(All-Yes)|sum(All-Nos)|sum(All-Unknown)|  
+----+------------+------------+----------------+  
|Male|          18|           5|               1|  
+----+------------+------------+----------------+  
</code></pre>
</div>

<h2 id="references">References</h2>
<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p><a href="https://spark.apache.org">Apache Spark</a>&nbsp;<a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p><a href="https://hadoop.apache.org">Apache Hadoop</a>&nbsp;<a href="#fnref:2" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:3">
      <p><a href="https://www.learningjournal.guru/courses/spark/spark-foundation-training/">Learning Journal</a>&nbsp;<a href="#fnref:3" class="reversefootnote">&#8617;</a>&nbsp;<a href="#fnref:3:1" class="reversefootnote">&#8617;<sup>2</sup></a></p>
    </li>
    <li id="fn:4">
      <p><a href="https://databricks.com/blog/2016/07/14/a-tale-of-three-apache-spark-apis-rdds-dataframes-and-datasets.html">RDDs vs Data Frames and Data Sets</a> A Tale of Three Apache Spark APIs: RDDs vs DataFrames and Datasets - When to use them and why&nbsp;<a href="#fnref:4" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>

        
      </section>

      <footer class="page__meta">
        
        


  




  
  
  

  <p class="page__taxonomy">
    <strong><i class="fa fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="http://localhost:4000/tags/#apache-spark" class="page__taxonomy-item" rel="tag">apache spark</a><span class="sep">, </span>
    
      
      
      <a href="http://localhost:4000/tags/#big-data" class="page__taxonomy-item" rel="tag">big data</a><span class="sep">, </span>
    
      
      
      <a href="http://localhost:4000/tags/#hadoop" class="page__taxonomy-item" rel="tag">hadoop</a><span class="sep">, </span>
    
      
      
      <a href="http://localhost:4000/tags/#real-time-data-pipelines" class="page__taxonomy-item" rel="tag">real time data pipelines</a><span class="sep">, </span>
    
      
      
      <a href="http://localhost:4000/tags/#scala" class="page__taxonomy-item" rel="tag">scala</a>
    
    </span>
  </p>




      </footer>

      

<section class="page__share">
  
    <h4 class="page__share-title">Share on</h4>
  

  <a href="https://twitter.com/intent/tweet?text=http://localhost:4000/posts/2020/02/blog-post-spark/" class="btn btn--twitter" title="Share on Twitter"><i class="fa fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/posts/2020/02/blog-post-spark/" class="btn btn--facebook" title="Share on Facebook"><i class="fa fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://plus.google.com/share?url=http://localhost:4000/posts/2020/02/blog-post-spark/" class="btn btn--google-plus" title="Share on Google Plus"><i class="fa fa-fw fa-google-plus" aria-hidden="true"></i><span> Google+</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/posts/2020/02/blog-post-spark/" class="btn btn--linkedin" title="Share on LinkedIn"><i class="fa fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>

      


  <nav class="pagination">
    
      <a href="http://localhost:4000/posts/2020/01/blog-post-kafka/" class="pagination--pager" title="Building a real-time big data pipeline (part 1: Apache Kafka)
">Previous</a>
    
    
      <a href="#" class="pagination--pager disabled">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
</div>


    </script>

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->
<!--<a href="/sitemap/">Sitemap</a> -->
<!-- end custom footer snippets -->

        

<!--
<div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
    
    
      <li><a href="http://github.com/adinasarapu"><i class="fa fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
      <li><a href="http://bitbucket.org/adinasarapu"><i class="fa fa-fw fa-bitbucket" aria-hidden="true"></i> Bitbucket</a></li>
    
    <li><a href="http://localhost:4000/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>
-->

<div class="page__footer-copyright">&copy; 2020 Ashok R. Dinasarapu  | <a href="http://adinasarapu.github.io/terms/" rel="nofollow">Privacy Policy</a>

<!-- Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>, a fork of <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.--> 
</div>

      </footer>
    </div>

    <script src="http://localhost:4000/assets/js/main.min.js"></script>




  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-68614074-1', 'auto');
  ga('send', 'pageview');
</script>






  </body>
</html>

