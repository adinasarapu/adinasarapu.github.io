

<!doctype html>
<html lang="en" class="no-js">
  <head>
    

<meta charset="utf-8">



<!-- begin SEO -->









<title>Building a real-time big data pipeline (10: Spark Streaming, Kafka, Java) - Ashok R. Dinasarapu Ph.D</title>







<meta property="og:locale" content="en-US">
<meta property="og:site_name" content="Ashok R. Dinasarapu Ph.D">
<meta property="og:title" content="Building a real-time big data pipeline (10: Spark Streaming, Kafka, Java)">


  <link rel="canonical" href="https://adinasarapu.github.io/posts/2021/01/blog-post-kafka-spark-streaming/">
  <meta property="og:url" content="https://adinasarapu.github.io/posts/2021/01/blog-post-kafka-spark-streaming/">



  <meta property="og:description" content="Updated on February 08, 2021">





  

  





  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2021-01-19T00:00:00-05:00">








  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Ashok R. Dinasarapu",
      "url" : "https://adinasarapu.github.io",
      "sameAs" : null
    }
  </script>






<!-- end SEO -->


<link href="https://adinasarapu.github.io/feed.xml" type="application/atom+xml" rel="alternate" title="Ashok R. Dinasarapu Ph.D Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="https://adinasarapu.github.io/assets/css/main.css">

<meta http-equiv="cleartype" content="on">
    

<!-- start custom head snippets -->

<link rel="apple-touch-icon" sizes="57x57" href="https://adinasarapu.github.io/images/apple-touch-icon-57x57.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="60x60" href="https://adinasarapu.github.io/images/apple-touch-icon-60x60.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="72x72" href="https://adinasarapu.github.io/images/apple-touch-icon-72x72.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="76x76" href="https://adinasarapu.github.io/images/apple-touch-icon-76x76.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="114x114" href="https://adinasarapu.github.io/images/apple-touch-icon-114x114.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="120x120" href="https://adinasarapu.github.io/images/apple-touch-icon-120x120.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="144x144" href="https://adinasarapu.github.io/images/apple-touch-icon-144x144.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="152x152" href="https://adinasarapu.github.io/images/apple-touch-icon-152x152.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="180x180" href="https://adinasarapu.github.io/images/apple-touch-icon-180x180.png?v=M44lzPylqQ">
<link rel="icon" type="image/png" href="https://adinasarapu.github.io/images/favicon-32x32.png?v=M44lzPylqQ" sizes="32x32">
<link rel="icon" type="image/png" href="https://adinasarapu.github.io/images/android-chrome-192x192.png?v=M44lzPylqQ" sizes="192x192">
<link rel="icon" type="image/png" href="https://adinasarapu.github.io/images/favicon-96x96.png?v=M44lzPylqQ" sizes="96x96">
<link rel="icon" type="image/png" href="https://adinasarapu.github.io/images/favicon-16x16.png?v=M44lzPylqQ" sizes="16x16">
<link rel="manifest" href="https://adinasarapu.github.io/images/manifest.json?v=M44lzPylqQ">
<link rel="mask-icon" href="https://adinasarapu.github.io/images/safari-pinned-tab.svg?v=M44lzPylqQ" color="#000000">
<link rel="shortcut icon" href="/images/favicon.ico?v=M44lzPylqQ">
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-TileImage" content="https://adinasarapu.github.io/images/mstile-144x144.png?v=M44lzPylqQ">
<meta name="msapplication-config" content="https://adinasarapu.github.io/images/browserconfig.xml?v=M44lzPylqQ">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="https://adinasarapu.github.io/assets/css/academicons.css"/>

<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>

<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg"><a href="https://adinasarapu.github.io/">Ashok R. Dinasarapu Ph.D</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://adinasarapu.github.io/publications/">Publications</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://adinasarapu.github.io/teaching/">Teaching</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://adinasarapu.github.io/portfolio/">Big Data</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://adinasarapu.github.io/year-archive/">NGS | Proteomics</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://adinasarapu.github.io/cv/">Résumé</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    





<div id="main" role="main">
  


  <div class="sidebar sticky">
  



<div itemscope itemtype="http://schema.org/Person">

  <div class="author__avatar">
    
    	<img src="https://adinasarapu.github.io/images/profile.png" class="author__avatar" alt="Scientist, Bioinformatics">
    
  </div>

  <div class="author__content">
    <h3 class="author__name">Scientist, Bioinformatics</h3>
    <p class="author__bio">Bridging the gap between Genomics and Data Science</p>
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> Atlanta, GA</li>
      
      
      
      
        <li><a href="mailto:ashok.reddy.dinasarapu@emory.edu"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i> Email</a></li>
      
      
       
        <li><a href="https://www.researchgate.net/profile/Ashok_Dinasarapu"><i class="fab fa-fw fa-researchgate" aria-hidden="true"></i> ResearchGate</a></li>
      
      
        <li><a href="https://twitter.com/adinasarapu"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
      
      
      
      
        <li><a href="https://www.linkedin.com/in/dareddy"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
      
      
      
      
      
        <li><a href="https://bitbucket.org/adinasarapu"><i class="fab fa-fw fa-bitbucket" aria-hidden="true"></i> Bitbucket</a></li>
      
      
        <li><a href="https://github.com/adinasarapu"><i class="fab fa-fw fa-github" aria-hidden="true"></i> Github</a></li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
        <li><a href="https://scholar.google.com/citations?user=b6GBykAAAAAJ"><i class="fas fa-fw fa-graduation-cap"></i> Google Scholar</a></li>
      
      
        <li><a href="https://pubmed.ncbi.nlm.nih.gov/?term=dinasarapu+ashok+OR+D+ashok+reddy&sort=pubdate"><i class="ai ai-pubmed-square ai-fw"></i> PubMed</a></li>
      
      
        <li><a href="http://orcid.org/0000-0002-1423-1518"><i class="ai ai-orcid-square ai-fw"></i> ORCID</a></li>
      
      
      
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="Building a real-time big data pipeline (10: Spark Streaming, Kafka, Java)">
    <meta itemprop="description" content="Updated on February 08, 2021">
    <meta itemprop="datePublished" content="January 19, 2021">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 class="page__title" itemprop="headline">Building a real-time big data pipeline (10: Spark Streaming, Kafka, Java)
</h1>
          
        
        
        
          <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2021-01-19T00:00:00-05:00">January 19, 2021</time></p>
        
        
             
        
    
        </header>
      

      <section class="page__content" itemprop="text">
        <p><em>Updated on February 08, 2021</em></p>

<p><a href="https://kafka.apache.org/">Apache Kafka</a> is a scalable, high performance and low latency platform for handling of real-time data feeds. Kafka allows reading and writing streams of data like a messaging system; written in Scala and Java. Kafka requires <a href="https://zookeeper.apache.org/">Apache Zookeeper</a> which is a coordination service that gives you the tools you need to write correct distributed applications. You need to have Java installed before running ZooKeeper. Kafka v2.5.0 (scala v2.12 build) and zookeeper (v3.4.13) were installed using docker.</p>

<p><a href="https://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a> is an extension of the core Apache Spark platform that enables scalable, high-throughput, fault-tolerant processing of data streams; written in Scala but offers Scala, Java, R and Python APIs to work with. It takes data from the sources like Kafka, Flume, Kinesis, HDFS, S3 or Twitter. This data can be further processed using complex algorithms. The final output, which is the processed data can be pushed out to destinations such as HDFS filesystems, databases, and live dashboards. Spark Streaming allows you to use <em>Machine Learning</em> applications to the data streams for advanced data processing. Spark uses Hadoop’s client libraries for distributed storage (HDFS) and resource management (YARN).</p>

<p>Figure source <a href="https://www.cuelogic.com/blog/analyzing-data-streaming-using-spark-vs-kafka">https://www.cuelogic.com</a><br />
<img src="/images/spark-streaming.png" alt="spark-streaming" /></p>

<p>Spark Streaming provides a high-level abstraction that represents a continuous data stream. This abstraction of the data stream is called discretized stream or DStream. This DStream can either be created from the data streams from the sources such as Kafka, Flume, and Kinesis or other DStreams by applying high-level operations on them.</p>

<p>Figure source <a href="https://www.cuelogic.com/blog/analyzing-data-streaming-using-spark-vs-kafka">https://www.cuelogic.com</a><br />
<img src="/images/DStreams-sequences.png" alt="DStreams-sequences" /></p>

<h3 id="kafka-installation">Kafka installation</h3>

<p>See my other blog for installation and starting kafka service <a href="https://adinasarapu.github.io/posts/2020/01/blog-post-kafka/">Kafka and Zookeeper with Docker</a>.</p>

<p>First install docker desktop and create docker-compose.yml file for Zookeeper and Kafka services. The first image is zookeeper (this service listens to port 2181). Kafka requires zookeeper to keep track of various brokers. The second service is kafka itself and here we are just running a single instance of it i.e one broker. Ideally, you would want to use multiple brokers in order to leverage the distributed architecture of Kafka.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>version: '3'  
services:  
  zookeeper:  
    image: wurstmeister/zookeeper  
    ports:  
      - "2181:2181"  
  kafka:  
   image: wurstmeister/kafka  
    ports:  
      - "9092:9092"  
    environment:  
     KAFKA_ADVERTISED_HOST_NAME: localhost  
     KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181  
     KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"  
    volumes:  
     - /var/run/docker.sock:/var/run/docker.sock
</code></pre></div></div>

<p>The kafka service environment variables.</p>

<p><code class="language-plaintext highlighter-rouge">KAFKA_ADVERTISED_HOST_NAME: localhost</code><br />
This is the address at which Kafka is running, and where producers and consumers can find it).</p>

<p><code class="language-plaintext highlighter-rouge">KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181</code><br />
This is for the hostname and port number of your zookeeper service. We named hostname as <code class="language-plaintext highlighter-rouge">zookeeper</code>.</p>

<p>Run the following commands in the directory where docker-compose.yml file is present.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker-compose up -d 
docker-compose exec kafka bash  
</code></pre></div></div>

<p>Change the directory to <code class="language-plaintext highlighter-rouge">/opt/kafka/bin</code> where you find scripts such as <code class="language-plaintext highlighter-rouge">kafka-topics.sh</code>.</p>

<p>The Kafka cluster stores streams of records in categories called topics. Once we start zookeeper and kafka locally, we can proceed to create our first topic, named <code class="language-plaintext highlighter-rouge">mytopic</code>. The producer clients can then publish streams of data (messages) to the said topic (mytopic) and consumers can read the said datastream, if they are subscribed to that particular topic.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bash-4.4# ./kafka-topics.sh \  
   --create \  
   --topic mytopic \  
   --partitions 1 \  
   --replication-factor 1 \  
   --bootstrap-server localhost:9092  
</code></pre></div></div>

<p>A Kafka topic is divided into one or more partitions. A partition contains an unchangeable sequence of records/messages. Each record/message in a partition is assigned and identified by its unique offset. If you set replication factor of a topic as 3, i.e., there will always be three copies of your data. This replication is performed at the level of topic-partitions.</p>

<p>To verify a topic’s partitions and  replication factor:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bash-4.4# ./kafka-topic.sh --zookeeper localhost:2181 --topic mytopic --describe
</code></pre></div></div>

<h3 id="java-application">Java Application</h3>

<p>Create a new Maven enabled project in Eclipse IDE and update the <code class="language-plaintext highlighter-rouge">pom.xml</code> file for <code class="language-plaintext highlighter-rouge">spark-core, spark-streaming, spark-streaming-kafka and spark-sql</code> libraries.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;dependencies&gt;
 &lt;dependency&gt;  
  &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;  
  &lt;artifactId&gt;spark-core_2.12&lt;/artifactId&gt;  
  &lt;version&gt;3.0.0&lt;/version&gt;  
 &lt;/dependency&gt;  
 &lt;dependency&gt;  
  &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;  
  &lt;artifactId&gt;spark-streaming_2.12&lt;/artifactId&gt;  
  &lt;version&gt;3.0.0&lt;/version&gt;  
  &lt;scope&gt;provided&lt;/scope&gt;  
 &lt;/dependency&gt;  
  &lt;dependency&gt;  
  &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;  
  &lt;artifactId&gt;spark-streaming-kafka-0-10_2.12&lt;/artifactId&gt;  
  &lt;version&gt;3.0.0&lt;/version&gt;  
 &lt;/dependency&gt;  
 &lt;dependency&gt;  
  &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;  
  &lt;artifactId&gt;spark-sql_2.12&lt;/artifactId&gt;  
  &lt;version&gt;3.0.0&lt;/version&gt;  
 &lt;/dependency&gt;  
&lt;/dependencies&gt;
</code></pre></div></div>

<p>Create a Java class with the following content</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>package com.example.spark;  

import java.util.Arrays;  
import java.util.Collection;  
import java.util.HashMap;  
import java.util.Map;  

import org.apache.kafka.clients.consumer.ConsumerRecord;  
import org.apache.spark.SparkConf;  
import org.apache.spark.streaming.Durations;  
import org.apache.spark.streaming.api.java.JavaDStream;  
import org.apache.spark.streaming.api.java.JavaInputDStream;  
import org.apache.spark.streaming.api.java.JavaStreamingContext;  
import org.apache.spark.streaming.kafka010.ConsumerStrategies;  
import org.apache.spark.streaming.kafka010.KafkaUtils;  
import org.apache.spark.streaming.kafka010.LocationStrategies;  

import org.apache.kafka.common.serialization.StringDeserializer;  

import org.apache.log4j.Level;  
import org.apache.log4j.Logger;  

public class JavaSparkApp {  
	public static void main(String[] args) throws InterruptedException {  
		// Firstly, we'll begin by initializing the JavaStreamingContext which is the entry point for all Spark Streaming applications:  
		Logger.getLogger("org").setLevel(Level.ALL);  
		Logger.getLogger("akka").setLevel(Level.ALL);  

		SparkConf sparkConf = new SparkConf();  
		sparkConf.setMaster("local");  
		sparkConf.set("spark.serializer", "org.apache.spark.serializer.KryoSerializer");  
		sparkConf.setAppName("WordCountingApp");  

		JavaStreamingContext streamingContext = new JavaStreamingContext(sparkConf, Durations.seconds(1));  

		// Now, we can connect to the Kafka topic from the JavaStreamingContext.  
	
		Map&lt;String, Object&gt; kafkaParams = new HashMap&lt;&gt;();  
		kafkaParams.put("bootstrap.servers", "localhost:9092");  
		kafkaParams.put("key.deserializer", StringDeserializer.class);  
		kafkaParams.put("value.deserializer", StringDeserializer.class);  
		kafkaParams.put("group.id", "group_test2");  
		kafkaParams.put("auto.offset.reset", "latest");  
		kafkaParams.put("enable.auto.commit", false);  

		Collection&lt;String&gt; topics = Arrays.asList("mytopic");  

		JavaInputDStream&lt;ConsumerRecord&lt;String, String&gt;&gt; messages = KafkaUtils.createDirectStream(streamingContext, 
			LocationStrategies.PreferConsistent(),  
			ConsumerStrategies.&lt;String, String&gt;Subscribe(topics, kafkaParams));  
		JavaDStream&lt;String&gt; data = messages.map(v -&gt; { return v.value(); });  
		
		data.print();  
		
		streamingContext.start();  
		streamingContext.awaitTermination();  
	}  
}  
</code></pre></div></div>

<p>Compile/run the above cretaed Java class and then run the console producer to write a few events into your topic.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;bash-4.4# ./kafka-console-producer.sh  
	--broker-list localhost:9092  
	--topic mytopic
&gt;hello  
&gt;here is my message  
</code></pre></div></div>

<p>The above (producer) messages will be published in Eclipse console as …</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-------------------------------------------  
Time: 1593889650000 ms  
-------------------------------------------  
hello  

-------------------------------------------  
Time: 1593889670000 ms  
-------------------------------------------  
here is my message  
</code></pre></div></div>

<p>You now have a rough picture of how Kafka and Spark Streaming works. For your own use case, you need to set a hostname which is not localhost, you need multiple such brokers to be a part of your kafka cluster and finally you need to set up a producer client application like the above java consumer client application.</p>

<p>You can shut down docker-compose by executing the following command in another terminal.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bash-4.4# exit  

$docker-compose down  
</code></pre></div></div>

<h2 id="useful-links">Useful links</h2>
<p><a href="https://www.instaclustr.com/the-power-of-kafka-partitions-how-to-get-the-most-out-of-your-kafka-cluster/">The Power of Kafka Partitions : How to Get the Most out of Your Kafka Cluster</a> by Paul Brebner<br />
<a href="https://linuxhint.com/docker_compose_kafka/">Deploy Apache Kafka using Docker Compose</a> by Ranvir Singh</p>

        
      </section>

      <footer class="page__meta">
        
        


  




  
  
  

  <p class="page__taxonomy">
    <strong><i class="fa fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="https://adinasarapu.github.io/tags/#apache-kafka" class="page__taxonomy-item" rel="tag">apache kafka</a><span class="sep">, </span>
    
      
      
      <a href="https://adinasarapu.github.io/tags/#big-data" class="page__taxonomy-item" rel="tag">big data</a><span class="sep">, </span>
    
      
      
      <a href="https://adinasarapu.github.io/tags/#bioinformatics" class="page__taxonomy-item" rel="tag">bioinformatics</a><span class="sep">, </span>
    
      
      
      <a href="https://adinasarapu.github.io/tags/#docker" class="page__taxonomy-item" rel="tag">docker</a><span class="sep">, </span>
    
      
      
      <a href="https://adinasarapu.github.io/tags/#emory-university" class="page__taxonomy-item" rel="tag">emory University</a><span class="sep">, </span>
    
      
      
      <a href="https://adinasarapu.github.io/tags/#java" class="page__taxonomy-item" rel="tag">java</a><span class="sep">, </span>
    
      
      
      <a href="https://adinasarapu.github.io/tags/#kafka" class="page__taxonomy-item" rel="tag">kafka</a><span class="sep">, </span>
    
      
      
      <a href="https://adinasarapu.github.io/tags/#real-time-data-pipelines" class="page__taxonomy-item" rel="tag">real time data pipelines</a><span class="sep">, </span>
    
      
      
      <a href="https://adinasarapu.github.io/tags/#spark-streaming" class="page__taxonomy-item" rel="tag">spark streaming</a><span class="sep">, </span>
    
      
      
      <a href="https://adinasarapu.github.io/tags/#yaml" class="page__taxonomy-item" rel="tag">YAML</a><span class="sep">, </span>
    
      
      
      <a href="https://adinasarapu.github.io/tags/#zookeeper" class="page__taxonomy-item" rel="tag">zookeeper</a>
    
    </span>
  </p>




      </footer>

      

<section class="page__share">
  
    <h4 class="page__share-title">Share on</h4>
  

  <a href="https://twitter.com/intent/tweet?text=https://adinasarapu.github.io/posts/2021/01/blog-post-kafka-spark-streaming/" class="btn btn--twitter" title="Share on Twitter"><i class="fab fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https://adinasarapu.github.io/posts/2021/01/blog-post-kafka-spark-streaming/" class="btn btn--facebook" title="Share on Facebook"><i class="fab fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://adinasarapu.github.io/posts/2021/01/blog-post-kafka-spark-streaming/" class="btn btn--linkedin" title="Share on LinkedIn"><i class="fab fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>

      


  <nav class="pagination">
    
      <a href="https://adinasarapu.github.io/posts/2020/12/blog-post-pyspark-mllib/" class="pagination--pager" title="Building a real-time big data pipeline (9: Spark MLlib, Regression, Python)
">Previous</a>
    
    
      <a href="https://adinasarapu.github.io/posts/2021/02/blog-post-kafka-spark-streaming/" class="pagination--pager" title="Building a real-time big data pipeline (11: Spark SQL Streaming, Kafka, Python)
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
</div>


    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->
<!--<a href="/cv/">Resume</a> -->
<!-- end custom footer snippets -->

        

<div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
    
    
      <li><a href="http://github.com/adinasarapu"><i class="fab fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
      <li><a href="http://bitbucket.org/adinasarapu"><i class="fab fa-bitbucket" aria-hidden="true"></i> Bitbucket</a></li>
    
    <!--<li><a href="https://adinasarapu.github.io/feed.xml">
	<i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>-->
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2023 Ashok R. Dinasarapu. 101 Woodruff Circle, Woodruff Memorial Research Building,  Room#6302, Emory University, Atlanta, GA 30322.</div>

      </footer>
    </div>

    <script src="https://adinasarapu.github.io/assets/js/main.min.js"></script>




  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'G-RWM39QLMPF', 'auto');
  ga('send', 'pageview');
</script>






  </body>
</html>

